{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image \n",
    "import imageio\n",
    "from einops import rearrange \n",
    "from tqdm import tqdm \n",
    "\n",
    "import wandb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "torch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"torch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVAE Model\n",
    "\n",
    "### Creating the CVAE model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# CVAE IMPLEMENTATION \n",
    "#######################################################\n",
    "\n",
    "class CVAE(nn.Module): \n",
    "    def __init__(self, input_dim=38_804, h1_dim=1024, h2_dim=512, h3_dim=256, latent_dim=100): \n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder Layers \n",
    "        self.fc1 = nn.Linear(input_dim, h1_dim)\n",
    "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
    "        self.fc41 = nn.Linear(h3_dim, latent_dim)  # mu \n",
    "        self.fc42 = nn.Linear(h3_dim, latent_dim)  # log var \n",
    "\n",
    "        # Decoder Layers \n",
    "        self.fc5 = nn.Linear(latent_dim, h1_dim)\n",
    "        self.fc6 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.fc7 = nn.Linear(h2_dim, input_dim)\n",
    "    \n",
    "    def encode(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        The encoder portion of the CVAE. \n",
    "\n",
    "        Args: \n",
    "            x (Tensor): Input data of shape [batch_size, 178 x 218], flattened images.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: The mean and log-variance of the approximate posterior \n",
    "            distribution q(z|x), where z is the latent variable. \n",
    "        '''\n",
    "\n",
    "        h1 = F.relu(self.fc1(x)) \n",
    "        h2 = self.fc2(h1)\n",
    "        h3 = F.relu(self.fc3(h2))\n",
    "        mu = self.fc41(h3)\n",
    "        logvar = self.fc42(h3) \n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Reparametrization trick standard in CVAE's. \n",
    "\n",
    "        Args: \n",
    "            mu: The mean of the approximate posterior distribution: q(z|x)\n",
    "            logvar: The log-variance of the approximate posterior distribution: q(z|x)\n",
    "        \n",
    "        Returns: \n",
    "            z: The latent variable sampled from q(z|x) using the reparametrization trick.\n",
    "            z is size [batch_size, latent_dim], in this case, latent_dim=100.\n",
    "        ''' \n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        z = mu + std * eps \n",
    "        return z \n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        The decoder portion of CVAE. \n",
    "\n",
    "        Args: \n",
    "            z: The latent variable. \n",
    "\n",
    "        Returns: \n",
    "            x_recon: The reconstructed x sampled from the learned distribution of the decoder. \n",
    "            In this case, x_recon is a reconstructred picture. \n",
    "        '''\n",
    "        h1 = F.relu(self.fc5(z))\n",
    "        h2 = F.relu(self.fc6(h1))\n",
    "        x_recon = F.sigmoid(self.fc7(h2))\n",
    "\n",
    "        return x_recon\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]: \n",
    "        \"\"\"\n",
    "        The forward pass on the CVAE. \n",
    "        \"\"\"\n",
    "\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        \n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4701, 0.1257, 0.5507,  ..., 0.8940, 0.2528, 0.5957]])\n",
      "Shape: torch.Size([1, 38804])\n",
      "Reconstructed x: tensor([[0.5289, 0.5155, 0.5113,  ..., 0.4947, 0.5665, 0.5084]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Shape of x_recon: torch.Size([1, 38804])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CVAE TESTING CELL \n",
    "\"\"\"\n",
    " \n",
    "test_x = torch.rand([1, 178 * 218])   # Test \"picture\"\n",
    "print(test_x)\n",
    "print(\"Shape:\", test_x.size())\n",
    "\n",
    "# Test the forward pass.\n",
    "cvae = CVAE() \n",
    "x_recon, mu, logvar = cvae.forward(test_x)\n",
    "print(\"Reconstructed x:\", x_recon)\n",
    "print(\"Shape of x_recon:\", x_recon.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-generator-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
